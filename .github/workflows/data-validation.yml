name: Data Validation

on:
  push:
    paths:
      - 'data/**'
    branches: [ main ]
  pull_request:
    paths:
      - 'data/**'
    branches: [ main ]
  workflow_dispatch:  # 수동 실행 가능

jobs:
  validate-data:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: 3.9
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-validation-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-validation-
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install pandas numpy h5py scipy matplotlib
        # 설치된 패키지 목록 출력 (디버깅용)
        pip list
        
    - name: Create data directories
      run: |
        echo "Creating data directory structure..."
        mkdir -p data/samples
        mkdir -p data/plots
        
    - name: Generate sample data if not exists
      run: |
        echo "Checking if sample data needs to be generated..."
        if [ -z "$(find data/samples -name '*.csv' 2>/dev/null)" ]; then
          echo "Generating sample data..."
          
          python - <<'EOF'
import numpy as np
import os
import pandas as pd

print("테스트용 데이터 생성 중...")

# 샘플링 빈도와 시간 간격 설정
sampling_rate = 1000  # Hz
duration = 1.0        # seconds
time = np.arange(0, duration, 1/sampling_rate)
samples = len(time)

# 샘플 신경 신호 데이터 생성 (1000개 샘플 × 4 채널)
np.random.seed(42)
synthetic_data = np.random.normal(0, 0.5, (samples, 4))

# 스파이크 패턴 추가
spike_positions = [100, 300, 500, 700, 900]
for pos in spike_positions:
    if pos < samples:
        synthetic_data[pos, :] += np.random.uniform(3, 5, 4)

# 저장 경로 확인
os.makedirs('data/samples', exist_ok=True)

# 정상 신경 신호 데이터 저장
df = pd.DataFrame(synthetic_data, columns=['channel_1', 'channel_2', 'channel_3', 'channel_4'])
df.insert(0, 'time', time)  # 시간 열 추가
df.to_csv('data/samples/normal_neural_signal.csv', index=False)
print("- 정상 신경 신호 데이터 저장 완료")

# 손상된 신경 신호 데이터 생성 및 저장
damaged_data = synthetic_data.copy()
damaged_data[200:400, 1:3] *= 0.1  # 일부 채널 손상 시뮬레이션
df_damaged = pd.DataFrame(damaged_data, columns=['channel_1', 'channel_2', 'channel_3', 'channel_4'])
df_damaged.insert(0, 'time', time)
df_damaged.to_csv('data/samples/damaged_neural_signal.csv', index=False)
print("- 손상된 신경 신호 데이터 저장 완료")

# 자극 반응 신호 데이터 생성 및 저장
stim_response = np.zeros((samples, 4))
for i in range(100, samples, 200):
    if i+20 <= samples:
        stim_response[i:i+20, :] = np.random.uniform(1, 3, (20, 4))
df_stim = pd.DataFrame(stim_response, columns=['channel_1', 'channel_2', 'channel_3', 'channel_4'])
df_stim.insert(0, 'time', time)
df_stim.to_csv('data/samples/stim_response_signal.csv', index=False)
print("- 자극 반응 신호 데이터 저장 완료")

# 잡음이 많은 신호 데이터 생성 및 저장
noisy_data = synthetic_data.copy()
noisy_data += np.random.normal(0, 1.5, noisy_data.shape)  # 추가 잡음
df_noisy = pd.DataFrame(noisy_data, columns=['channel_1', 'channel_2', 'channel_3', 'channel_4'])
df_noisy.insert(0, 'time', time)
df_noisy.to_csv('data/samples/noisy_neural_signal.csv', index=False)
print("- 잡음이 많은 신호 데이터 저장 완료")

# 멀티채널 신경 신호 데이터 생성 및 저장 (8채널)
multichannel_data = np.random.normal(0, 0.5, (samples, 8))
for pos in spike_positions:
    if pos < samples:
        multichannel_data[pos, :] += np.random.uniform(2, 4, 8)
df_multi = pd.DataFrame(multichannel_data, 
                         columns=[f'channel_{i+1}' for i in range(8)])
df_multi.insert(0, 'time', time)
df_multi.to_csv('data/samples/multichannel_neural_signal.csv', index=False)
print("- 멀티채널 신경 신호 데이터 저장 완료")

print("데이터 생성 완료.")
print(f"총 {len(os.listdir('data/samples'))} 개의 CSV 파일 생성됨.")
print(f"파일 목록: {', '.join(os.listdir('data/samples'))}")

EOF
        else
          echo "Sample data already exists:"
          ls -la data/samples/
        fi
        
    - name: Validate CSV files
      run: |
        echo "Validating CSV files..."
        
        python - <<'EOF'
import os
import pandas as pd
import numpy as np
import glob
import sys

# 검증 중 발견된 오류 기록
errors = []

# CSV 파일 검증
csv_files = glob.glob('data/samples/*.csv')
print(f'Found {len(csv_files)} CSV files to validate')

for csv_file in csv_files:
    try:
        print(f'Validating {csv_file}...')
        df = pd.read_csv(csv_file)
        
        # 기본 검증: 열 존재 확인
        if 'time' not in df.columns:
            errors.append(f'{csv_file}: Missing required "time" column')
        
        # 데이터 형식 검증
        if not all(df.dtypes.apply(lambda x: np.issubdtype(x, np.number))):
            errors.append(f'{csv_file}: Not all columns contain numeric data')
        
        # 시간 열 검증: 단조 증가하는지 확인
        if 'time' in df.columns and len(df) > 1:
            if not (df['time'].diff().dropna() >= 0).all():
                errors.append(f'{csv_file}: Time column is not monotonically increasing')
        
        # 신호 값 검증: 너무 큰 값이나 NaN 확인
        for col in df.columns:
            if col != 'time':
                if df[col].isna().any():
                    errors.append(f'{csv_file}: Column {col} contains NaN values')
                
                # 극단치 확인 (절대값 100 이상은 의심스러운 값)
                extreme_values = df[abs(df[col]) > 100]
                if not extreme_values.empty:
                    errors.append(f'{csv_file}: Column {col} contains extreme values (abs > 100)')
        
        print(f'Successfully validated {csv_file}: {len(df)} rows, {len(df.columns)} columns')
    except Exception as e:
        errors.append(f'Error validating {csv_file}: {str(e)}')

# 오류 보고 및 종료
if errors:
    print('\nValidation errors found:')
    for error in errors:
        print(f'- {error}')
    # 경고만 출력하고 종료하지는 않음
    print("\nErrors detected but continuing workflow...")
else:
    print('\nAll data files validated successfully!')
EOF
        
    - name: Generate sample plots
      run: |
        echo "Generating sample plots..."
        
        python - <<'EOF'
import os
import pandas as pd
import matplotlib.pyplot as plt
import glob
import sys

# 각 CSV 파일에 대한 플롯 생성
csv_files = glob.glob('data/samples/*.csv')
print(f'Found {len(csv_files)} CSV files to plot')

success_count = 0
error_count = 0

# plots 디렉토리 생성
os.makedirs('data/plots', exist_ok=True)

for csv_file in csv_files:
    try:
        base_name = os.path.basename(csv_file).replace('.csv', '')
        print(f'Plotting {base_name}...')
        
        # CSV 파일 로드
        df = pd.read_csv(csv_file)
        
        if 'time' not in df.columns:
            print(f'WARNING: {csv_file} has no time column, skipping')
            continue
            
        # 플롯 생성
        plt.figure(figsize=(10, 6))
        
        # 시간 축 범위 설정 (최소 1초)
        x_min = df['time'].min()
        x_max = max(df['time'].max(), x_min + 1.0)
        
        # 채널 열 찾기
        channel_cols = [col for col in df.columns if col != 'time']
        
        # 각 채널에 대한 플롯
        for col in channel_cols:
            plt.plot(df['time'], df[col], label=col)
        
        # 다중 채널인 경우 범례 추가
        if len(channel_cols) > 1:
            plt.legend()
        
        plt.title(f'{base_name}')
        plt.xlabel('Time (s)')
        plt.ylabel('Amplitude')
        plt.grid(True)
        plt.xlim(x_min, x_max)
        
        # Y축 범위 설정 (데이터 기반)
        data_min = df[channel_cols].min().min()
        data_max = df[channel_cols].max().max()
        margin = (data_max - data_min) * 0.1
        plt.ylim(data_min - margin, data_max + margin)
        
        # 플롯 저장
        plot_path = f'data/plots/{base_name}.png'
        plt.savefig(plot_path, dpi=100, bbox_inches='tight')
        plt.close()
        
        print(f'Generated plot for {base_name} at {plot_path}')
        success_count += 1
        
    except Exception as e:
        print(f'Error generating plot for {csv_file}: {str(e)}')
        error_count += 1

print(f'\nPlotting complete: {success_count} successful, {error_count} failed')
if success_count == 0:
    print("No plots were generated successfully! Check your data.")
    sys.exit(1)  # 모든 플롯 생성이 실패한 경우에만 실패로 처리
EOF
        
    - name: Upload plots as artifacts
      uses: actions/upload-artifact@v3
      if: always()  # 이전 단계에서 실패하더라도 항상 실행
      with:
        name: data-plots
        path: data/plots/
        retention-days: 5
