{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경 신호 데이터 전처리 및 특성 추출\n",
    "\n",
    "이 노트북은 적응형 신경 전기자극 시스템에서 사용되는 신경 신호 데이터의 전처리 및 특성 추출 과정을 다룹니다. 효과적인 전기자극을 위해서는 신경 신호에서 유의미한 정보를 추출하는 것이 중요합니다. 이를 통해 신경 손상 정도와 재생 상태를 더 정확하게 평가할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "# 스타일 설정\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# 디렉토리 설정\n",
    "sys.path.append('..')\n",
    "from utils.data_utils import load_neural_data, save_processed_data\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "data_path = '../data/neural_recordings/'\n",
    "\n",
    "# 데이터 파일 목록 확인\n",
    "data_files = glob.glob(os.path.join(data_path, '*.csv'))\n",
    "print(f\"발견된 데이터 파일: {len(data_files)}\")\n",
    "for file in data_files:\n",
    "    print(f\" - {os.path.basename(file)}\")\n",
    "\n",
    "# 데이터 로드 함수 (실제로는 utils에 구현)\n",
    "def load_sample_data():\n",
    "    # 샘플 데이터 생성 (실제 데이터가 없는 경우)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 3개의 서로 다른 신경 상태 시뮬레이션\n",
    "    n_samples = 1000\n",
    "    time = np.linspace(0, 10, n_samples)\n",
    "    \n",
    "    # 정상 상태 (주파수가 높고 규칙적인 신호)\n",
    "    normal_signal = np.sin(2 * np.pi * 5 * time) + 0.5 * np.sin(2 * np.pi * 10 * time)\n",
    "    normal_signal += np.random.normal(0, 0.2, n_samples)\n",
    "    \n",
    "    # 손상 상태 (불규칙적이고 진폭이 낮은 신호)\n",
    "    damaged_signal = 0.5 * np.sin(2 * np.pi * 2 * time) + 0.2 * np.sin(2 * np.pi * 7.5 * time)\n",
    "    damaged_signal += np.random.normal(0, 0.5, n_samples)\n",
    "    \n",
    "    # 재생 상태 (규칙성이 회복되고 있는 신호)\n",
    "    recovery_signal = 0.8 * np.sin(2 * np.pi * 4 * time) + 0.3 * np.sin(2 * np.pi * 8.5 * time)\n",
    "    recovery_signal += np.random.normal(0, 0.3, n_samples)\n",
    "    \n",
    "    # 여러 채널의 신호 결합\n",
    "    signals = np.column_stack([\n",
    "        normal_signal, damaged_signal, recovery_signal,\n",
    "        normal_signal + np.random.normal(0, 0.1, n_samples),\n",
    "        damaged_signal + np.random.normal(0, 0.1, n_samples),\n",
    "        recovery_signal + np.random.normal(0, 0.1, n_samples)\n",
    "    ])\n",
    "    \n",
    "    # 레이블 생성 (0: 정상, 1: 손상, 2: 재생)\n",
    "    labels = np.zeros(n_samples, dtype=int)\n",
    "    labels[n_samples//3:(2*n_samples)//3] = 1  # 손상 상태\n",
    "    labels[(2*n_samples)//3:] = 2  # 재생 상태\n",
    "    \n",
    "    return {\n",
    "        'signals': signals,\n",
    "        'labels': labels,\n",
    "        'time': time,\n",
    "        'channel_names': ['채널1', '채널2', '채널3', '채널4', '채널5', '채널6']\n",
    "    }\n",
    "\n",
    "# 데이터 로드\n",
    "try:\n",
    "    data = load_neural_data(data_path)\n",
    "    print(f\"실제 데이터를 성공적으로 로드했습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"실제 데이터 로드 실패: {e}\\n샘플 데이터를 대신 생성합니다.\")\n",
    "    data = load_sample_data()\n",
    "\n",
    "# 데이터 기본 정보 출력\n",
    "print(f\"데이터 형태: {data['signals'].shape}\")\n",
    "print(f\"채널 수: {data['signals'].shape[1]}\")\n",
    "print(f\"샘플 수: {data['signals'].shape[0]}\")\n",
    "print(f\"레이블 클래스: {np.unique(data['labels'])}\")\n",
    "print(f\"레이블 분포:\\n{pd.Series(data['labels']).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 시각화 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신호 시각화 함수\n",
    "def plot_signals(signals, time, labels, channel_names, n_channels=3, window_size=200):\n",
    "    # 클래스별 색상 정의\n",
    "    colors = ['#2ca02c', '#d62728', '#1f77b4']\n",
    "    class_names = ['정상', '손상', '재생']\n",
    "    \n",
    "    # 시각화할 채널 선택 (최대 n_channels)\n",
    "    n_vis_channels = min(n_channels, signals.shape[1])\n",
    "    selected_channels = range(n_vis_channels)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_vis_channels, 1, figsize=(15, 3*n_vis_channels), sharex=True)\n",
    "    if n_vis_channels == 1:\n",
    "        axes = [axes]\n",
    "        \n",
    "    for i, channel in enumerate(selected_channels):\n",
    "        # 배경색으로 레이블 구분\n",
    "        for label_value in np.unique(labels):\n",
    "            mask = (labels == label_value)\n",
    "            axes[i].fill_between(\n",
    "                time[mask], \n",
    "                np.min(signals[:window_size, channel])*1.1, \n",
    "                np.max(signals[:window_size, channel])*1.1, \n",
    "                color=colors[label_value], \n",
    "                alpha=0.2, \n",
    "                label=class_names[label_value] if i == 0 else None\n",
    "            )\n",
    "        \n",
    "        # 신호 플롯 (처음 window_size 샘플만)\n",
    "        axes[i].plot(time[:window_size], signals[:window_size, channel], 'k-', lw=1)\n",
    "        axes[i].set_ylabel(f'{channel_names[channel]}')\n",
    "        axes[i].set_xlim(time[0], time[window_size-1])\n",
    "        \n",
    "    axes[-1].set_xlabel('시간 (초)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 범례 추가 (첫 번째 차트에만)\n",
    "    if n_vis_channels > 0:\n",
    "        handles, labels = axes[0].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.02), ncol=3)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "# 신호 시각화\n",
    "plot_signals(data['signals'], data['time'], data['labels'], data['channel_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신호의 스펙트럼 분석\n",
    "def plot_spectrum(signals, sampling_rate, labels, channel_names, n_channels=3):\n",
    "    # 각 클래스별 대표 구간 선택\n",
    "    class_indices = {}\n",
    "    for label in np.unique(labels):\n",
    "        indices = np.where(labels == label)[0]\n",
    "        class_indices[label] = indices[len(indices)//2]  # 각 클래스의 중간 지점\n",
    "    \n",
    "    # 시각화할 채널 선택\n",
    "    n_vis_channels = min(n_channels, signals.shape[1])\n",
    "    selected_channels = range(n_vis_channels)\n",
    "    \n",
    "    # 각 채널별, 클래스별 스펙트럼 시각화\n",
    "    fig, axes = plt.subplots(n_vis_channels, len(class_indices), figsize=(15, 3*n_vis_channels), sharey='row')\n",
    "    \n",
    "    # 단일 채널 또는 단일 클래스인 경우 축 조정\n",
    "    if n_vis_channels == 1 and len(class_indices) == 1:\n",
    "        axes = np.array([[axes]])  \n",
    "    elif n_vis_channels == 1:\n",
    "        axes = np.array([axes])\n",
    "    elif len(class_indices) == 1:\n",
    "        axes = np.array([[ax] for ax in axes])\n",
    "    \n",
    "    class_names = ['정상', '손상', '재생']\n",
    "    window_size = 256  # FFT 윈도우 크기\n",
    "    \n",
    "    for i, channel in enumerate(selected_channels):\n",
    "        for j, (label, index) in enumerate(class_indices.items()):\n",
    "            # 클래스별 대표 구간에서 데이터 추출\n",
    "            segment = signals[index:index+window_size, channel]\n",
    "            \n",
    "            # FFT 계산\n",
    "            fft_result = fft(segment)\n",
    "            fft_mag = np.abs(fft_result[:window_size//2])\n",
    "            freqs = fftfreq(window_size, 1/sampling_rate)[:window_size//2]\n",
    "            \n",
    "            # 스펙트럼 플롯\n",
    "            axes[i, j].plot(freqs, fft_mag, 'k-')\n",
    "            axes[i, j].set_title(f'{channel_names[channel]} - {class_names[label]}')\n",
    "            axes[i, j].set_xlabel('주파수 (Hz)')\n",
    "            \n",
    "            # 첫 번째 채널의 첫 번째 클래스에만 y축 레이블 추가\n",
    "            if j == 0:\n",
    "                axes[i, j].set_ylabel('진폭')\n",
    "                \n",
    "            # x축 범위 설정\n",
    "            axes[i, j].set_xlim(0, sampling_rate/2)  # 나이퀴스트 주파수까지\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 스펙트럼 시각화 (샘플링 레이트는 예시)\n",
    "sampling_rate = 100  # 가정: 100 Hz 샘플링\n",
    "plot_spectrum(data['signals'], sampling_rate, data['labels'], data['channel_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 신호 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 전처리 함수들\n",
    "def preprocess_signals(signals, sampling_rate):\n",
    "    \"\"\"신경 신호에 대한 기본 전처리 수행\"\"\"\n",
    "    # 채널 수 확인\n",
    "    n_samples, n_channels = signals.shape\n",
    "    processed_signals = np.zeros_like(signals)\n",
    "    \n",
    "    for ch in range(n_channels):\n",
    "        # 1. 기준선 제거 (고역 통과 필터)\n",
    "        b, a = signal.butter(4, 0.5/(sampling_rate/2), 'highpass')\n",
    "        baseline_removed = signal.filtfilt(b, a, signals[:, ch])\n",
    "        \n",
    "        # 2. 노이즈 제거 (60Hz 노치 필터 - 전원 노이즈)\n",
    "        b, a = signal.iirnotch(60, 30, sampling_rate)\n",
    "        notch_filtered = signal.filtfilt(b, a, baseline_removed)\n",
    "        \n",
    "        # 3. 대역 통과 필터 (관심 주파수 대역 추출 예: 0.5-100Hz)\n",
    "        b, a = signal.butter(4, [0.5/(sampling_rate/2), 100/(sampling_rate/2)], 'bandpass')\n",
    "        bandpass_filtered = signal.filtfilt(b, a, notch_filtered)\n",
    "        \n",
    "        processed_signals[:, ch] = bandpass_filtered\n",
    "    \n",
    "    return processed_signals\n",
    "\n",
    "# 신호 전처리 적용\n",
    "processed_signals = preprocess_signals(data['signals'], sampling_rate)\n",
    "\n",
    "# 전처리 전/후 비교\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# 원본 신호\n",
    "plt.subplot(2, 1, 1)\n",
    "window_size = 200  # 처음 200개 샘플만 표시\n",
    "for ch in range(min(3, data['signals'].shape[1])):\n",
    "    plt.plot(data['time'][:window_size], data['signals'][:window_size, ch], \n",
    "             label=f'{data[\"channel_names\"][ch]} (원본)')\n",
    "plt.legend()\n",
    "plt.title('원본 신호')\n",
    "plt.ylabel('진폭')\n",
    "\n",
    "# 전처리된 신호\n",
    "plt.subplot(2, 1, 2)\n",
    "for ch in range(min(3, processed_signals.shape[1])):\n",
    "    plt.plot(data['time'][:window_size], processed_signals[:window_size, ch], \n",
    "             label=f'{data[\"channel_names\"][ch]} (전처리됨)')\n",
    "plt.legend()\n",
    "plt.title('전처리된 신호')\n",
    "plt.xlabel('시간 (초)')\n",
    "plt.ylabel('진폭')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 특성 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 도메인 특성 추출\n",
    "def extract_time_features(signals, window_size=128, step=64):\n",
    "    \"\"\"시간 도메인 특성 추출\"\"\"\n",
    "    n_samples, n_channels = signals.shape\n",
    "    n_windows = (n_samples - window_size) // step + 1\n",
    "    \n",
    "    # 각 윈도우의 시작 인덱스\n",
    "    window_starts = [i * step for i in range(n_windows)]\n",
    "    \n",
    "    # 특성 저장 배열\n",
    "    features = np.zeros((n_windows, n_channels * 5))  # 채널당 5개 특성\n",
    "    \n",
    "    for i, start in enumerate(window_starts):\n",
    "        window = signals[start:start+window_size, :]\n",
    "        \n",
    "        for ch in range(n_channels):\n",
    "            ch_data = window[:, ch]\n",
    "            \n",
    "            # 평균\n",
    "            features[i, ch*5 + 0] = np.mean(ch_data)\n",
    "            # 표준편차\n",
    "            features[i, ch*5 + 1] = np.std(ch_data)\n",
    "            # 첨도 (Kurtosis)\n",
    "            features[i, ch*5 + 2] = np.mean((ch_data - np.mean(ch_data))**4) / (np.std(ch_data)**4)\n",
    "            # 왜도 (Skewness)\n",
    "            features[i, ch*5 + 3] = np.mean((ch_data - np.mean(ch_data))**3) / (np.std(ch_data)**3)\n",
    "            # 제로 교차율 (Zero-crossing rate)\n",
    "            features[i, ch*5 + 4] = np.sum(np.abs(np.diff(np.signbit(ch_data)))) / (2 * len(ch_data))\n",
    "    \n",
    "    # 특성 이름 생성\n",
    "    feature_names = []\n",
    "    for ch in range(n_channels):\n",
    "        channel_name = f'채널{ch+1}'\n",
    "        feature_names.extend([\n",
    "            f'{channel_name}_평균',\n",
    "            f'{channel_name}_표준편차',\n",
    "            f'{channel_name}_첨도',\n",
    "            f'{channel_name}_왜도',\n",
    "            f'{channel_name}_제로교차율'\n",
    "        ])\n",
    "    \n",
    "    # 윈도우 레이블 (각 윈도우의 중간점에 해당하는 레이블 사용)\n",
    "    window_labels = np.array([data['labels'][start + window_size//2] for start in window_starts])\n",
    "    \n",
    "    return features, window_labels, feature_names, window_starts\n",
    "\n",
    "# 주파수 도메인 특성 추출\n",
    "def extract_frequency_features(signals, sampling_rate, window_size=128, step=64):\n",
    "    \"\"\"주파수 도메인 특성 추출\"\"\"\n",
    "    n_samples, n_channels = signals.shape\n",
    "    n_windows = (n_samples - window_size) // step + 1\n",
    "    \n",
    "    # 각 윈도우의 시작 인덱스\n",
    "    window_starts = [i * step for i in range(n_windows)]\n",
    "    \n",
    "    # 주파수 대역 정의 (Hz)\n",
    "    bands = {\n",
    "        'delta': (0.5, 4),\n",
    "        'theta': (4, 8),\n",
    "        'alpha': (8, 13),\n",
    "        'beta': (13, 30),\n",
    "        'gamma': (30, 100)\n",
    "    }\n",
    "    \n",
    "    # 특성 저장 배열\n",
    "    features = np.zeros((n_windows, n_channels * len(bands)))  # 채널당 5개 대역 특성\n",
    "    \n",
    "    for i, start in enumerate(window_starts):\n",
    "        window = signals[start:start+window_size, :]\n",
    "        \n",
    "        for ch in range(n_channels):\n",
    "            ch_data = window[:, ch]\n",
    "            \n",
    "            # FFT 계산\n",
    "            fft_result = fft(ch_data)\n",
    "            fft_mag = np.abs(fft_result[:window_size//2])\n",
    "            freqs = fftfreq(window_size, 1/sampling_rate)[:window_size//2]\n",
    "            \n",
    "            # 주파수 대역별 파워 계산\n",
    "            for j, (band_name, (low_freq, high_freq)) in enumerate(bands.items()):\n",
    "                band_mask = (freqs >= low_freq) & (freqs <= high_freq)\n",
    "                if np.any(band_mask):  # 해당 대역에 주파수가 있는지 확인\n",
    "                    band_power = np.sum(fft_mag[band_mask] ** 2)\n",
    "                    features[i, ch * len(bands) + j] = band_power\n",
    "    \n",
    "    # 특성 이름 생성\n",
    "    feature_names = []\n",
    "    for ch in range(n_channels):\n",
    "        channel_name = f'채널{ch+1}'\n",
    "        for band_name in bands.keys():\n",
    "            feature_names.append(f'{channel_name}_{band_name}')\n",
    "    \n",
    "    # 윈도우 레이블 (각 윈도우의 중간점에 해당하는 레이블 사용)\n",
    "    window_labels = np.array([data['labels'][start + window_size//2] for start in window_starts])\n",
    "    \n",
    "    return features, window_labels, feature_names, window_starts\n",
    "\n",
    "# 특성 추출\n",
    "time_features, time_labels, time_feature_names, window_starts = extract_time_features(processed_signals)\n",
    "freq_features, freq_labels, freq_feature_names, _ = extract_frequency_features(processed_signals, sampling_rate)\n",
    "\n",
    "# 특성 결합\n",
    "all_features = np.hstack((time_features, freq_features))\n",
    "all_feature_names = time_feature_names + freq_feature_names\n",
    "\n",
    "print(f\"시간 도메인 특성: {time_features.shape} (특성 수: {len(time_feature_names)})\")\n",
    "print(f\"주파수 도메인 특성: {freq_features.shape} (특성 수: {len(freq_feature_names)})\")\n",
    "print(f\"결합된 특성: {all_features.shape} (총 특성 수: {len(all_feature_names)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 특성 분석 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 중요도 시각화 (상위 10개 특성)\n",
    "def plot_feature_importance(features, labels, feature_names, n_top=10):\n",
    "    \"\"\"특성 중요도 계산 및 시각화\"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # 랜덤 포레스트 모델 훈련\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(features, labels)\n",
    "    \n",
    "    # 특성 중요도 정렬\n",
    "    importance = rf.feature_importances_\n",
    "    indices = np.argsort(importance)[::-1][:n_top]\n",
    "    \n",
    "    # 시각화\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title(f'상위 {n_top}개 특성 중요도')\n",
    "    plt.bar(range(n_top), importance[indices], align='center')\n",
    "    plt.xticks(range(n_top), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 상위 특성 목록 반환\n",
    "    return [(feature_names[i], importance[i]) for i in indices]\n",
    "\n",
    "# 특성 중요도 시각화\n",
    "top_features = plot_feature_importance(all_features, time_labels, all_feature_names)\n",
    "print(\"\\n상위 특성 목록:\")\n",
    "for name, importance in top_features:\n",
    "    print(f\"{name}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA를 통한 차원 축소 및 시각화\n",
    "def plot_pca_visualization(features, labels, feature_names):\n",
    "    \"\"\"PCA를 통한 특성 차원 축소 및 시각화\"\"\"\n",
    "    # 데이터 정규화\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # PCA 적용\n",
    "    pca = PCA(n_components=2)\n",
    "    features_pca = pca.fit_transform(features_scaled)\n",
    "    \n",
    "    # 결과 시각화\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # 클래스별 색상 및 마커 정의\n",
    "    colors = ['#2ca02c', '#d62728', '#1f77b4']\n",
    "    markers = ['o', 's', '^']\n",
    "    class_names = ['정상', '손상', '재생']\n",
    "    \n",
    "    for i, label in enumerate(np.unique(labels)):\n",
    "        plt.scatter(\n",
    "            features_pca[labels == label, 0],\n",
    "            features_pca[labels == label, 1],\n",
    "            c=colors[i],\n",
    "            marker=markers[i],\n",
    "            alpha=0.7,\n",
    "            label=class_names[i]\n",
    "        )\n",
    "    \n",
    "    plt.title('PCA 시각화')\n",
    "    plt.xlabel(f'PC1 (설명 분산: {pca.explained_variance_ratio_[0]:.2%})')\n",
    "    plt.ylabel(f'PC2 (설명 분산: {pca.explained_variance_ratio_[1]:.2%})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return features_pca, pca\n",
    "\n",
    "# PCA 시각화\n",
    "features_pca, pca = plot_pca_visualization(all_features, time_labels, all_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 웨이블릿 변환을 통한 시간-주파수 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wavelet_analysis(signal, sampling_rate, channel_name):\n",
    "    \"\"\"웨이블릿 변환을 통한 시간-주파수 분석\"\"\"\n",
    "    # 분석할 데이터 (한 채널만)\n",
    "    window_size = 512  # 분석 윈도우 크기\n",
    "    data = signal[:window_size]\n",
    "    time = np.arange(len(data)) / sampling_rate\n",
    "    \n",
    "    # 웨이블릿 변환을 위한 스케일 설정\n",
    "    scales = np.arange(1, 128)\n",
    "    \n",
    "    # 웨이블릿 변환 수행 (Morlet 웨이블릿 사용)\n",
    "    coefficients, frequencies = pywt.cwt(data, scales, 'morl', 1/sampling_rate)\n",
    "    \n",
    "    # 결과 시각화\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # 원본 신호\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(time, data)\n",
    "    plt.title(f'{channel_name} 원본 신호')\n",
    "    plt.xlabel('시간 (초)')\n",
    "    plt.ylabel('진폭')\n",
    "    \n",
    "    # 웨이블릿 변환 결과 (스칼로그램)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(np.abs(coefficients), \n",
    "               extent=[time.min(), time.max(), frequencies[-1], frequencies[0]], \n",
    "               aspect='auto', \n",
    "               cmap='jet')\n",
    "    plt.colorbar(label='진폭')\n",
    "    plt.title(f'{channel_name} 웨이블릿 변환 (스칼로그램)')\n",
    "    plt.xlabel('시간 (초)')\n",
    "    plt.ylabel('주파수 (Hz)')\n",
    "    plt.ylim([0, 50])  # 주요 주파수 영역만 표시\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 웨이블릿 분석 (첫 번째 채널 데이터 사용)\n",
    "plot_wavelet_analysis(processed_signals[:, 0], sampling_rate, data['channel_names'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 신경 상태별 특성 분포 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경 상태별 주요 특성 분포 시각화\n",
    "def plot_feature_distributions(features, labels, feature_names, top_n=5):\n",
    "    \"\"\"상위 특성들의 클래스별 분포 시각화\"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # 특성 중요도 계산\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(features, labels)\n",
    "    importance = rf.feature_importances_\n",
    "    top_indices = np.argsort(importance)[::-1][:top_n]\n",
    "    top_features = [feature_names[i] for i in top_indices]\n",
    "    \n",
    "    # 클래스 이름 정의\n",
    "    class_names = ['정상', '손상', '재생']\n",
    "    \n",
    "    # 각 상위 특성별 분포 시각화\n",
    "    plt.figure(figsize=(15, 3*top_n))\n",
    "    \n",
    "    for i, (idx, feature_name) in enumerate(zip(top_indices, top_features)):\n",
    "        plt.subplot(top_n, 1, i+1)\n",
    "        \n",
    "        # 클래스별 분포 (바이올린 플롯)\n",
    "        sns.violinplot(\n",
    "            x=[class_names[label] for label in labels],\n",
    "            y=features[:, idx],\n",
    "            palette=['#2ca02c', '#d62728', '#1f77b4'],\n",
    "            inner='quartile'\n",
    "        )\n",
    "        \n",
    "        plt.title(f'{feature_name} 분포 (중요도: {importance[idx]:.4f})')\n",
    "        plt.xlabel('신경 상태')\n",
    "        plt.ylabel('특성값')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 상위 5개 특성의 분포 시각화\n",
    "plot_feature_distributions(all_features, time_labels, all_feature_names, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 특성 상관관계 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 상관관계 시각화\n",
    "def plot_feature_correlations(features, feature_names, n_top=10):\n",
    "    \"\"\"상위 특성들 간의 상관관계 시각화\"\"\"\n",
    "    # 상위 특성들만 선택\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    # 특성 중요도로 상위 특성 선택\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(features, time_labels)\n",
    "    importance = rf.feature_importances_\n",
    "    top_indices = np.argsort(importance)[::-1][:n_top]\n",
    "    \n",
    "    # 상위 특성 추출\n",
    "    top_features = features[:, top_indices]\n",
    "    top_feature_names = [feature_names[i] for i in top_indices]\n",
    "    \n",
    "    # 특성 정규화\n",
    "    scaler = MinMaxScaler()\n",
    "    top_features_scaled = scaler.fit_transform(top_features)\n",
    "    \n",
    "    # 상관관계 계산\n",
    "    corr_matrix = np.corrcoef(top_features_scaled.T)\n",
    "    \n",
    "    # 시각화 (히트맵)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        corr_matrix, \n",
    "        annot=True, \n",
    "        cmap='coolwarm', \n",
    "        xticklabels=top_feature_names,\n",
    "        yticklabels=top_feature_names,\n",
    "        vmin=-1, vmax=1\n",
    "    )\n",
    "    plt.title('상위 특성 간 상관관계')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 상위 10개 특성간 상관관계 시각화\n",
    "plot_feature_correlations(all_features, all_feature_names, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 전처리된 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 특성 데이터 저장\n",
    "def save_processed_features(features, labels, feature_names, output_path):\n",
    "    \"\"\"전처리된 특성 데이터 저장\"\"\"\n",
    "    # 디렉토리 생성\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # 특성과 레이블을 DataFrame으로 변환\n",
    "    df = pd.DataFrame(features, columns=feature_names)\n",
    "    df['label'] = labels\n",
    "    \n",
    "    # CSV 파일로 저장\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"전처리된 특성 데이터가 {output_path}에 저장되었습니다.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 전처리된 특성 데이터 저장\n",
    "output_path = '../data/processed/neural_features.csv'\n",
    "feature_df = save_processed_features(all_features, time_labels, all_feature_names, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 결론 및 다음 단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북에서는 신경 신호 데이터에 대한 전처리와 특성 추출 과정을 수행했습니다. 주요 단계는 다음과 같습니다:\n",
    "\n",
    "1. **데이터 로드 및 시각화**: 원본 신호를 확인하고 기본적인 특성을 분석했습니다.\n",
    "2. **신호 전처리**: 기준선 제거, 노이즈 제거, 대역 통과 필터링을 통해 신호 품질을 향상시켰습니다.\n",
    "3. **특성 추출**: 시간 및 주파수 도메인 특성을 추출하여 각 신경 상태를 정량적으로 표현했습니다.\n",
    "4. **특성 분석 및 시각화**: 특성 중요도, PCA, 웨이블릿 분석, 특성 분포 등을 통해 데이터의 패턴을 분석했습니다.\n",
    "5. **데이터 저장**: 전처리된 특성 데이터를 저장하여 후속 모델링에 활용할 수 있도록 했습니다.\n",
    "\n",
    "### 다음 단계:\n",
    "\n",
    "1. **머신러닝 모델 개발**: 추출된 특성을 사용하여 신경 상태 분류 모델을 개발합니다.\n",
    "2. **실시간 처리 구현**: 전처리 및 특성 추출 과정을 실시간으로 처리할 수 있는 파이프라인을 구축합니다.\n",
    "3. **특성 선택 최적화**: 모델 성능 향상을 위해 특성 선택 방법을 개선합니다.\n",
    "4. **고급 시간-주파수 분석**: 보다 복잡한 신호 패턴을 포착하기 위한 고급 분석 기법을 적용합니다.\n",
    "5. **신경 상태 변화 추적**: 시간에 따른 신경 상태 변화를 추적하고 분석하는 방법을 개발합니다.\n",
    "\n",
    "이러한 분석은 적응형 신경 전기자극 시스템의 정확성과 효과를 향상시키는 데 중요한 역할을 할 것입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}