{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 기반 신경 신호 분류 및 예측\n",
    "\n",
    "이 노트북은 적응형 신경 전기자극 시스템에서 LSTM(Long Short-Term Memory) 네트워크를 사용하여 신경 신호를 분류하고 예측하는 방법을 설명합니다. LSTM은 시계열 데이터 처리에 탁월한 성능을 보이는 순환 신경망(RNN)의 한 종류로, 신경 신호와 같은 시간에 따른 패턴을 학습하는 데 이상적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# 경로 설정\n",
    "sys.path.append('..')\n",
    "from utils.data_utils import load_neural_data, preprocess_neural_signals\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "data_path = '../data/neural_recordings/'\n",
    "signals_data = load_neural_data(data_path)\n",
    "\n",
    "# 데이터 확인\n",
    "print(f\"데이터 형태: {signals_data['signals'].shape}\")\n",
    "print(f\"레이블 수: {len(signals_data['labels'])}\")\n",
    "print(f\"레이블 클래스: {np.unique(signals_data['labels'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "X, y, feature_names = preprocess_neural_signals(signals_data['signals'], signals_data['labels'])\n",
    "\n",
    "# 데이터 분할 (훈련, 검증, 테스트)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# LSTM을 위한 3D 형태로 변환 [samples, time steps, features]\n",
    "# 여기서는 각 시계열을 10개의 타임스텝으로 분할합니다\n",
    "def reshape_for_lstm(X, time_steps):\n",
    "    samples, features = X.shape\n",
    "    # 타임스텝으로 나누어지는 샘플 수 계산\n",
    "    valid_samples = samples // time_steps * time_steps\n",
    "    # 유효한 샘플만 선택\n",
    "    X_valid = X[:valid_samples]\n",
    "    # LSTM 형태로 재구성\n",
    "    X_reshaped = X_valid.reshape(valid_samples // time_steps, time_steps, features)\n",
    "    return X_reshaped\n",
    "\n",
    "time_steps = 10\n",
    "X_train_lstm = reshape_for_lstm(X_train_scaled, time_steps)\n",
    "X_val_lstm = reshape_for_lstm(X_val_scaled, time_steps)\n",
    "X_test_lstm = reshape_for_lstm(X_test_scaled, time_steps)\n",
    "\n",
    "# 레이블도 동일하게 변환\n",
    "y_train_lstm = y_train[:len(X_train_lstm) * time_steps:time_steps]\n",
    "y_val_lstm = y_val[:len(X_val_lstm) * time_steps:time_steps]\n",
    "y_test_lstm = y_test[:len(X_test_lstm) * time_steps:time_steps]\n",
    "\n",
    "print(f\"LSTM 훈련 데이터 형태: {X_train_lstm.shape}\")\n",
    "print(f\"LSTM 검증 데이터 형태: {X_val_lstm.shape}\")\n",
    "print(f\"LSTM 테스트 데이터 형태: {X_test_lstm.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LSTM 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        # 첫 번째 LSTM 층\n",
    "        Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # 두 번째 LSTM 층\n",
    "        Bidirectional(LSTM(32)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # 출력 층\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 입력 형태 및 클래스 수 정의\n",
    "input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# 모델 생성\n",
    "lstm_model = build_lstm_model(input_shape, num_classes)\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 정의\n",
    "checkpoint_path = \"../models/lstm_neural_signal_model.h5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_path, \n",
    "    monitor='val_accuracy', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "history = lstm_model.fit(\n",
    "    X_train_lstm, y_train_lstm,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_lstm, y_val_lstm),\n",
    "    callbacks=[early_stopping, checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 시각화\n",
    "def plot_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # 손실 곡선\n",
    "    ax1.plot(history.history['loss'], label='훈련 손실')\n",
    "    ax1.plot(history.history['val_loss'], label='검증 손실')\n",
    "    ax1.set_title('손실 곡선')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('손실')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 정확도 곡선\n",
    "    ax2.plot(history.history['accuracy'], label='훈련 정확도')\n",
    "    ax2.plot(history.history['val_accuracy'], label='검증 정확도')\n",
    "    ax2.set_title('정확도 곡선')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('정확도')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 세트에서 모델 평가\n",
    "test_loss, test_acc = lstm_model.evaluate(X_test_lstm, y_test_lstm, verbose=1)\n",
    "print(f\"테스트 손실: {test_loss:.4f}\")\n",
    "print(f\"테스트 정확도: {test_acc:.4f}\")\n",
    "\n",
    "# 예측\n",
    "y_pred = lstm_model.predict(X_test_lstm)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# 혼동 행렬\n",
    "conf_matrix = confusion_matrix(y_test_lstm, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=np.unique(y),\n",
    "            yticklabels=np.unique(y))\n",
    "plt.title('혼동 행렬')\n",
    "plt.xlabel('예측 레이블')\n",
    "plt.ylabel('실제 레이블')\n",
    "plt.show()\n",
    "\n",
    "# 분류 보고서\n",
    "print(\"\\n분류 보고서:\")\n",
    "print(classification_report(y_test_lstm, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 신경 상태 예측 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 확률 시각화\n",
    "def plot_prediction_probabilities(model, X, y_true, class_names, n_samples=5):\n",
    "    # 무작위 샘플 선택\n",
    "    indices = np.random.choice(len(X), n_samples, replace=False)\n",
    "    X_selected = X[indices]\n",
    "    y_true_selected = y_true[indices]\n",
    "    \n",
    "    # 예측 확률 계산\n",
    "    y_probs = model.predict(X_selected)\n",
    "    \n",
    "    # 플롯 생성\n",
    "    fig, axes = plt.subplots(n_samples, 1, figsize=(12, 4*n_samples))\n",
    "    \n",
    "    for i, (probs, true_label, ax) in enumerate(zip(y_probs, y_true_selected, axes)):\n",
    "        # 확률 막대 그래프\n",
    "        bars = ax.bar(class_names, probs, color='skyblue')\n",
    "        \n",
    "        # 실제 레이블 강조\n",
    "        bars[true_label].set_color('green')\n",
    "        \n",
    "        # 예측 레이블 표시\n",
    "        pred_label = np.argmax(probs)\n",
    "        if pred_label != true_label:\n",
    "            bars[pred_label].set_color('red')\n",
    "        \n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.set_ylabel('확률')\n",
    "        ax.set_title(f'샘플 {i+1}: 실제 레이블 = {class_names[true_label]}, '\n",
    "                     f'예측 레이블 = {class_names[pred_label]}')\n",
    "        \n",
    "        # 확률값 표시\n",
    "        for bar, prob in zip(bars, probs):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                   f'{prob:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 클래스 이름 정의 (예시)\n",
    "class_names = [f'상태 {i}' for i in range(num_classes)]\n",
    "\n",
    "# 예측 확률 시각화\n",
    "plot_prediction_probabilities(lstm_model, X_test_lstm, y_test_lstm, class_names, n_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 적응형 전기자극 파라미터 추천 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태별 최적 전기자극 파라미터 정의 (예시)\n",
    "stimulation_parameters = {\n",
    "    0: {\n",
    "        'frequency': 20,  # Hz\n",
    "        'amplitude': 2.5, # mA\n",
    "        'pulse_width': 200, # µs\n",
    "        'duration': 30,   # minutes\n",
    "        'description': '낮은 강도 자극 - 초기 신경 손상 단계'\n",
    "    },\n",
    "    1: {\n",
    "        'frequency': 50,\n",
    "        'amplitude': 3.5,\n",
    "        'pulse_width': 300,\n",
    "        'duration': 45,\n",
    "        'description': '중간 강도 자극 - 활성화 촉진 단계'\n",
    "    },\n",
    "    2: {\n",
    "        'frequency': 100,\n",
    "        'amplitude': 5.0,\n",
    "        'pulse_width': 500,\n",
    "        'duration': 60,\n",
    "        'description': '높은 강도 자극 - 재생 가속화 단계'\n",
    "    }\n",
    "}\n",
    "\n",
    "# 패턴 기반 추천 함수\n",
    "def recommend_stimulation(model, signal_sequence, scaler, stimulation_parameters):\n",
    "    # 신호 정규화\n",
    "    signal_scaled = scaler.transform(signal_sequence)\n",
    "    \n",
    "    # LSTM 입력 형태로 변환\n",
    "    samples, features = signal_scaled.shape\n",
    "    signal_reshaped = signal_scaled.reshape(1, samples, features)\n",
    "    \n",
    "    # 상태 예측\n",
    "    state_probs = model.predict(signal_reshaped)[0]\n",
    "    predicted_state = np.argmax(state_probs)\n",
    "    confidence = state_probs[predicted_state]\n",
    "    \n",
    "    # 추천 파라미터\n",
    "    recommended_params = stimulation_parameters[predicted_state]\n",
    "    \n",
    "    return predicted_state, confidence, recommended_params\n",
    "\n",
    "# 예시 시연 (무작위 샘플 사용)\n",
    "sample_idx = np.random.randint(0, len(X_test_lstm))\n",
    "sample_sequence = X_test_lstm[sample_idx]\n",
    "true_state = y_test_lstm[sample_idx]\n",
    "\n",
    "# 원래 형태로 변환 (2D)\n",
    "sample_sequence_2d = sample_sequence.reshape(-1, sample_sequence.shape[-1])\n",
    "\n",
    "# 추천 실행\n",
    "predicted_state, confidence, recommended_params = recommend_stimulation(\n",
    "    lstm_model, sample_sequence_2d, scaler, stimulation_parameters\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"샘플의 실제 상태: {true_state} ({class_names[true_state]})\")\n",
    "print(f\"예측된 상태: {predicted_state} ({class_names[predicted_state]}) - 신뢰도: {confidence:.2f}\")\n",
    "print(\"\\n추천 전기자극 파라미터:\")\n",
    "for key, value in recommended_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 모델 저장 및 내보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model_save_path = \"../models/lstm_neural_signal_classifier\"\n",
    "lstm_model.save(model_save_path)\n",
    "print(f\"모델이 {model_save_path}에 저장되었습니다.\")\n",
    "\n",
    "# 스케일러 저장\n",
    "import joblib\n",
    "scaler_save_path = \"../models/lstm_signal_scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_save_path)\n",
    "print(f\"스케일러가 {scaler_save_path}에 저장되었습니다.\")\n",
    "\n",
    "# 전기자극 파라미터 저장\n",
    "import json\n",
    "params_save_path = \"../models/stimulation_parameters.json\"\n",
    "with open(params_save_path, 'w') as f:\n",
    "    # 정수 키를 문자열로 변환\n",
    "    str_params = {str(k): v for k, v in stimulation_parameters.items()}\n",
    "    json.dump(str_params, f, indent=4)\n",
    "print(f\"전기자극 파라미터가 {params_save_path}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 결론 및 다음 단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북에서는 LSTM 기반 신경 신호 분류 모델을 구축하고 학습하였습니다. 다음 단계로 고려할 수 있는 사항들은 다음과 같습니다:\n",
    "\n",
    "1. **하이퍼파라미터 최적화**: 그리드 서치 또는 베이지안 최적화를 통해 모델 하이퍼파라미터를 더 세밀하게 조정합니다.\n",
    "2. **모델 앙상블링**: 여러 모델을 결합하여 예측 성능을 향상시킵니다.\n",
    "3. **실시간 처리 구현**: 학습된 모델을 실시간 신호 처리 시스템에 통합합니다.\n",
    "4. **전기자극 파라미터 최적화**: 피드백 루프를 통해 전기자극 파라미터를 자동으로 최적화합니다.\n",
    "5. **임상 검증**: 실제 신경재생 환경에서 시스템의 효과를 검증합니다.\n",
    "\n",
    "이 시스템은 신경 손상 후 재생 과정에서 맞춤형 전기자극을 제공함으로써 회복 속도와 효과를 향상시키는 데 기여할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}