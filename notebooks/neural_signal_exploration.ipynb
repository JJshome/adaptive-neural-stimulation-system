{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경 신호 데이터 탐색 및 전처리\n",
    "\n",
    "이 노트북은 적응형 신경 전기자극 시스템에서 사용되는 신경 신호 데이터의 탐색 및 전처리 과정을 설명합니다. 여러 유형의 신경 신호 데이터를 로드하고, 기본적인 분석과 시각화를 수행하며, 모델 학습을 위한 전처리 단계를 시연합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필요한 라이브러리 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import os\n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 경고 메시지 숨기기\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 그래프 스타일 설정\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드 및 탐색\n",
    "\n",
    "이 섹션에서는 다양한 형식(CSV, NPY, HDF5)의 신경 신호 데이터를 로드하고 기본 특성을 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 폴더 경로 설정\n",
    "data_path = \"../data/samples/\"\n",
    "\n",
    "# 사용 가능한 데이터 파일 목록 확인\n",
    "if os.path.exists(data_path):\n",
    "    files = os.listdir(data_path)\n",
    "    csv_files = [f for f in files if f.endswith('.csv')]\n",
    "    npy_files = [f for f in files if f.endswith('.npy')]\n",
    "    h5_files = [f for f in files if f.endswith('.h5') or f.endswith('.hdf5')]\n",
    "    \n",
    "    print(f\"CSV 파일: {csv_files}\")\n",
    "    print(f\"NPY 파일: {npy_files}\")\n",
    "    print(f\"HDF5 파일: {h5_files}\")\n",
    "else:\n",
    "    print(f\"경로 {data_path}를 찾을 수 없습니다. 샘플 데이터를 먼저 생성해주세요.\")\n",
    "    # 샘플 폴더 생성\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    print(f\"{data_path} 디렉토리가 생성되었습니다. 이후 단계에서 샘플 데이터를 생성합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 샘플 데이터 생성 (필요시)\n",
    "\n",
    "데이터 파일이 존재하지 않는 경우, 분석을 위한 합성 신경 신호 데이터를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_data():\n",
    "    \"\"\"\n",
    "    다양한 유형의 신경 신호 데이터를 생성하고 저장합니다.\n",
    "    \"\"\"\n",
    "    # 샘플링 설정\n",
    "    sampling_rate = 1000  # Hz\n",
    "    duration = 5.0        # 초\n",
    "    time = np.arange(0, duration, 1/sampling_rate)\n",
    "    samples = len(time)\n",
    "    \n",
    "    # 랜덤 시드 설정 (재현성)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 1. 정상 신경 신호 생성\n",
    "    normal_data = np.random.normal(0, 0.5, (samples, 4))\n",
    "    \n",
    "    # 스파이크 패턴 추가\n",
    "    for channel in range(4):\n",
    "        # 각 채널에 랜덤한 위치에 스파이크 추가\n",
    "        spike_positions = np.random.choice(np.arange(100, samples-100), 20, replace=False)\n",
    "        for pos in spike_positions:\n",
    "            # 스파이크 모양: 빠른 상승, 느린 하강\n",
    "            normal_data[pos:pos+5, channel] = np.array([3, 4, 2, 1, 0.5])\n",
    "    \n",
    "    # 2. 손상된 신경 신호 생성\n",
    "    damaged_data = normal_data.copy()\n",
    "    # 일부 채널의 특정 구간에서 활동 감소\n",
    "    damaged_data[1000:3000, 1:3] *= 0.2\n",
    "    \n",
    "    # 3. 자극 반응 신호 생성\n",
    "    stim_response = np.zeros((samples, 4))\n",
    "    # 주기적 자극 패턴 (500ms 간격으로 자극)\n",
    "    for i in range(500, samples, 1000):\n",
    "        if i+100 <= samples:\n",
    "            for ch in range(4):\n",
    "                # 채널별 다른 반응 강도\n",
    "                response_amp = np.random.uniform(1.5, 3.0)\n",
    "                # 자극 직후 강한 반응, 점차 감소\n",
    "                decay = np.exp(-np.arange(100)/30)\n",
    "                stim_response[i:i+100, ch] = response_amp * decay\n",
    "    \n",
    "    # 4. 잡음이 많은 신호 생성\n",
    "    noisy_data = normal_data.copy()\n",
    "    # 가우시안 노이즈 추가\n",
    "    noisy_data += np.random.normal(0, 1.0, noisy_data.shape)\n",
    "    # 60Hz 전원 노이즈 추가\n",
    "    power_noise = 0.5 * np.sin(2 * np.pi * 60 * time).reshape(-1, 1)\n",
    "    noisy_data += power_noise\n",
    "    \n",
    "    # 5. 다채널 (8채널) 신경 신호 생성\n",
    "    multichannel_data = np.random.normal(0, 0.4, (samples, 8))\n",
    "    for channel in range(8):\n",
    "        # 채널별 기저 변동 추가\n",
    "        drift = 0.2 * np.sin(2 * np.pi * 0.1 * channel * time)\n",
    "        multichannel_data[:, channel] += drift\n",
    "        \n",
    "        # 스파이크 추가 (채널별 다른 빈도)\n",
    "        num_spikes = 10 + 5 * channel  # 채널 번호에 따라 스파이크 수 증가\n",
    "        spike_positions = np.random.choice(np.arange(100, samples-100), num_spikes, replace=False)\n",
    "        for pos in spike_positions:\n",
    "            spike_amp = 2.0 + 0.2 * channel  # 채널별 다른 스파이크 진폭\n",
    "            multichannel_data[pos:pos+5, channel] = spike_amp * np.array([0.5, 1, 0.8, 0.4, 0.2])\n",
    "    \n",
    "    # CSV 파일 저장\n",
    "    def save_data_as_csv(data, filename, channels=None):\n",
    "        if channels is None:\n",
    "            channels = [f'channel_{i+1}' for i in range(data.shape[1])]\n",
    "        df = pd.DataFrame(data, columns=channels)\n",
    "        df.insert(0, 'time', time)  # 시간 열 추가\n",
    "        df.to_csv(os.path.join(data_path, filename), index=False)\n",
    "        print(f\"{filename} 저장 완료\")\n",
    "    \n",
    "    # NPY 파일 저장\n",
    "    def save_data_as_npy(data, filename):\n",
    "        np.save(os.path.join(data_path, filename), data)\n",
    "        print(f\"{filename} 저장 완료\")\n",
    "    \n",
    "    # 모든 데이터 저장\n",
    "    save_data_as_csv(normal_data, \"normal_neural_signal.csv\")\n",
    "    save_data_as_csv(damaged_data, \"damaged_neural_signal.csv\")\n",
    "    save_data_as_csv(stim_response, \"stim_response_signal.csv\")\n",
    "    save_data_as_csv(noisy_data, \"noisy_neural_signal.csv\")\n",
    "    save_data_as_csv(multichannel_data, \"multichannel_neural_signal.csv\")\n",
    "    \n",
    "    save_data_as_npy(normal_data, \"normal_neural_signal.npy\")\n",
    "    save_data_as_npy(damaged_data, \"damaged_neural_signal.npy\")\n",
    "    save_data_as_npy(stim_response, \"stim_response_signal.npy\")\n",
    "    \n",
    "    # 데이터와 시간 배열을 함께 저장 (HDF5 형식)\n",
    "    with h5py.File(os.path.join(data_path, \"neural_signals.h5\"), 'w') as f:\n",
    "        f.create_dataset('time', data=time)\n",
    "        f.create_dataset('normal', data=normal_data)\n",
    "        f.create_dataset('damaged', data=damaged_data)\n",
    "        f.create_dataset('stim_response', data=stim_response)\n",
    "        f.create_dataset('noisy', data=noisy_data)\n",
    "        f.create_dataset('multichannel', data=multichannel_data)\n",
    "    print(\"neural_signals.h5 저장 완료\")\n",
    "    \n",
    "    return time, normal_data, damaged_data, stim_response, noisy_data, multichannel_data\n",
    "\n",
    "# 데이터 파일이 없으면 샘플 데이터 생성\n",
    "if not os.path.exists(os.path.join(data_path, \"normal_neural_signal.csv\")):\n",
    "    print(\"샘플 데이터 생성 중...\")\n",
    "    time, normal_data, damaged_data, stim_response, noisy_data, multichannel_data = generate_sample_data()\n",
    "    print(\"샘플 데이터 생성 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 CSV 데이터 로드 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 로드\n",
    "try:\n",
    "    normal_df = pd.read_csv(os.path.join(data_path, \"normal_neural_signal.csv\"))\n",
    "    damaged_df = pd.read_csv(os.path.join(data_path, \"damaged_neural_signal.csv\"))\n",
    "    stim_response_df = pd.read_csv(os.path.join(data_path, \"stim_response_signal.csv\"))\n",
    "    noisy_df = pd.read_csv(os.path.join(data_path, \"noisy_neural_signal.csv\"))\n",
    "    \n",
    "    # 정상 신경 신호 데이터 정보 출력\n",
    "    print(\"=== 정상 신경 신호 데이터 정보 ===\")\n",
    "    print(normal_df.info())\n",
    "    print(\"\\n처음 5행:\")\n",
    "    print(normal_df.head())\n",
    "    print(\"\\n기본 통계:\")\n",
    "    print(normal_df.describe())\n",
    "except FileNotFoundError:\n",
    "    print(\"CSV 파일을 찾을 수 없습니다. 먼저 샘플 데이터를 생성해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경 신호 데이터 시각화\n",
    "def plot_neural_signal(df, title, duration=1.0):\n",
    "    \"\"\"\n",
    "    신경 신호 데이터를 시각화합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        시각화할 신경 신호 데이터 (time 열 포함)\n",
    "    title : str\n",
    "        플롯 제목\n",
    "    duration : float\n",
    "        표시할 시간 구간 (초)\n",
    "    \"\"\"\n",
    "    # 모든 채널 열 선택 (time 열 제외)\n",
    "    channel_cols = [col for col in df.columns if col != 'time']\n",
    "    \n",
    "    # 표시할 샘플 수 계산\n",
    "    time_col = df['time']\n",
    "    samples_per_second = int(1 / (time_col[1] - time_col[0]))\n",
    "    display_samples = int(duration * samples_per_second)\n",
    "    \n",
    "    # 시각화\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for i, channel in enumerate(channel_cols):\n",
    "        # 채널별 오프셋 추가하여 겹치지 않게 표시\n",
    "        offset = i * 5\n",
    "        plt.plot(df['time'][:display_samples], \n",
    "                 df[channel][:display_samples] + offset, \n",
    "                 label=channel)\n",
    "    \n",
    "    # 플롯 설정\n",
    "    plt.title(f\"{title} (처음 {duration}초)\", fontsize=14)\n",
    "    plt.xlabel('시간 (초)', fontsize=12)\n",
    "    plt.ylabel('진폭 + 오프셋', fontsize=12)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 다양한 신경 신호 데이터 시각화\n",
    "try:\n",
    "    # 정상 신경 신호\n",
    "    plot_neural_signal(normal_df, \"정상 신경 신호\", duration=1.0)\n",
    "    \n",
    "    # 손상된 신경 신호\n",
    "    plot_neural_signal(damaged_df, \"손상된 신경 신호\", duration=1.0)\n",
    "    \n",
    "    # 자극 반응 신호\n",
    "    plot_neural_signal(stim_response_df, \"자극 반응 신호\", duration=2.0)\n",
    "    \n",
    "    # 잡음이 많은 신호\n",
    "    plot_neural_signal(noisy_df, \"잡음이 많은 신호\", duration=1.0)\n",
    "except NameError:\n",
    "    print(\"데이터가 로드되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 신호 전처리\n",
    "\n",
    "이 섹션에서는 신경 신호 데이터에 적용할 수 있는 다양한 전처리 기법을 시연합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 노이즈 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_neural_signal(signal_data, fs=1000, lowcut=5, highcut=200, order=4):\n",
    "    \"\"\"\n",
    "    신경 신호에 대역 통과 필터를 적용합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal_data : array-like\n",
    "        필터링할 신호 데이터\n",
    "    fs : float\n",
    "        샘플링 주파수 (Hz)\n",
    "    lowcut : float\n",
    "        저주파 차단 (Hz)\n",
    "    highcut : float\n",
    "        고주파 차단 (Hz)\n",
    "    order : int\n",
    "        필터 차수\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    filtered_data : array-like\n",
    "        필터링된 신호 데이터\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    filtered_data = signal.filtfilt(b, a, signal_data)\n",
    "    return filtered_data\n",
    "\n",
    "try:\n",
    "    # 잡음이 많은 신호에 대해 필터링 적용\n",
    "    noisy_signal = noisy_df['channel_1'].values\n",
    "    filtered_signal = filter_neural_signal(noisy_signal, lowcut=10, highcut=150)\n",
    "    \n",
    "    # 60Hz 노치 필터 적용 (전원 노이즈 제거)\n",
    "    fs = 1000  # 샘플링 주파수 (Hz)\n",
    "    notch_freq = 60.0  # 제거할 주파수 (Hz)\n",
    "    quality_factor = 30.0  # 필터 Q 인자\n",
    "    b_notch, a_notch = signal.iirnotch(notch_freq, quality_factor, fs)\n",
    "    notched_signal = signal.filtfilt(b_notch, a_notch, filtered_signal)\n",
    "    \n",
    "    # 원본 신호와 필터링된 신호 비교\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # 시간 도메인 비교\n",
    "    plt.subplot(2, 1, 1)\n",
    "    t = noisy_df['time'].values[:1000]  # 첫 1초 데이터\n",
    "    plt.plot(t, noisy_signal[:1000], 'b-', alpha=0.5, label='원본 신호')\n",
    "    plt.plot(t, filtered_signal[:1000], 'r-', alpha=0.7, label='대역 통과 필터링')\n",
    "    plt.plot(t, notched_signal[:1000], 'g-', alpha=0.7, label='노치 필터링')\n",
    "    plt.title('시간 도메인: 원본 vs 필터링된 신호', fontsize=14)\n",
    "    plt.xlabel('시간 (초)', fontsize=12)\n",
    "    plt.ylabel('진폭', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 주파수 도메인 비교\n",
    "    plt.subplot(2, 1, 2)\n",
    "    \n",
    "    def plot_spectrum(signal_data, fs, label):\n",
    "        # 신호의 주파수 스펙트럼 계산\n",
    "        n = len(signal_data)\n",
    "        yf = np.abs(fft(signal_data)/n)\n",
    "        xf = fftfreq(n, 1/fs)[:n//2]\n",
    "        plt.plot(xf[:int(250/fs*n)], 2.0*yf[:int(250/fs*n)], label=label, alpha=0.7)\n",
    "    \n",
    "    plot_spectrum(noisy_signal, fs, '원본 신호')\n",
    "    plot_spectrum(filtered_signal, fs, '대역 통과 필터링')\n",
    "    plot_spectrum(notched_signal, fs, '노치 필터링')\n",
    "    \n",
    "    plt.title('주파수 도메인: 원본 vs 필터링된 신호', fontsize=14)\n",
    "    plt.xlabel('주파수 (Hz)', fontsize=12)\n",
    "    plt.ylabel('진폭', fontsize=12)\n",
    "    plt.xlim(0, 250)  # 0-250Hz 범위만 표시\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except NameError:\n",
    "    print(\"데이터가 로드되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 스파이크 검출 및 특성 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spikes(signal_data, threshold_factor=4.0, min_distance=10):\n",
    "    \"\"\"\n",
    "    신호에서 스파이크를 검출합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal_data : array-like\n",
    "        스파이크를 검출할 신호 데이터\n",
    "    threshold_factor : float\n",
    "        신호 표준편차의 몇 배를 임계값으로 사용할지 결정\n",
    "    min_distance : int\n",
    "        검출된 스파이크 간 최소 샘플 거리\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    spike_indices : array-like\n",
    "        검출된 스파이크의 인덱스 배열\n",
    "    \"\"\"\n",
    "    # 표준편차 기반 임계값 계산\n",
    "    threshold = threshold_factor * np.std(signal_data)\n",
    "    \n",
    "    # 임계값을 초과하는 샘플 찾기\n",
    "    above_threshold = np.where(signal_data > threshold)[0]\n",
    "    \n",
    "    # 연속된 샘플을 하나의 스파이크로 그룹화\n",
    "    spike_indices = []\n",
    "    if len(above_threshold) > 0:\n",
    "        # 첫 번째 스파이크 추가\n",
    "        spike_indices.append(above_threshold[0])\n",
    "        \n",
    "        # 최소 거리 조건을 만족하는 스파이크 추가\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] - spike_indices[-1] >= min_distance:\n",
    "                spike_indices.append(above_threshold[i])\n",
    "    \n",
    "    return np.array(spike_indices)\n",
    "\n",
    "def extract_spike_features(signal_data, spike_indices, window_size=20):\n",
    "    \"\"\"\n",
    "    검출된 스파이크 주변 신호의 특성을 추출합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal_data : array-like\n",
    "        원본 신호 데이터\n",
    "    spike_indices : array-like\n",
    "        검출된 스파이크의 인덱스 배열\n",
    "    window_size : int\n",
    "        스파이크 특성 추출을 위한 윈도우 크기\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    features_dict : dict\n",
    "        스파이크별 특성 정보\n",
    "    \"\"\"\n",
    "    features_dict = {\n",
    "        'amplitude': [],       # 스파이크 진폭\n",
    "        'width': [],           # 스파이크 폭\n",
    "        'rise_time': [],       # 상승 시간\n",
    "        'decay_time': [],      # 감쇠 시간\n",
    "        'waveforms': []        # 스파이크 파형\n",
    "    }\n",
    "    \n",
    "    for idx in spike_indices:\n",
    "        # 스파이크 주변 윈도우 추출 (경계 검사)\n",
    "        start_idx = max(0, idx - window_size//2)\n",
    "        end_idx = min(len(signal_data), idx + window_size//2)\n",
    "        \n",
    "        if end_idx - start_idx < window_size:\n",
    "            continue  # 윈도우 크기가 충분하지 않으면 건너뜀\n",
    "            \n",
    "        waveform = signal_data[start_idx:end_idx]\n",
    "        features_dict['waveforms'].append(waveform)\n",
    "        \n",
    "        # 진폭 계산\n",
    "        amplitude = np.max(waveform) - np.min(waveform)\n",
    "        features_dict['amplitude'].append(amplitude)\n",
    "        \n",
    "        # 스파이크 폭 계산 (반높이 전폭)\n",
    "        half_amp = np.max(waveform) / 2\n",
    "        above_half = np.where(waveform > half_amp)[0]\n",
    "        if len(above_half) > 0:\n",
    "            width = above_half[-1] - above_half[0]\n",
    "            features_dict['width'].append(width)\n",
    "        else:\n",
    "            features_dict['width'].append(0)\n",
    "        \n",
    "        # 상승 및 감쇠 시간 계산\n",
    "        peak_idx = np.argmax(waveform)\n",
    "        rise_time = peak_idx\n",
    "        decay_time = len(waveform) - peak_idx - 1\n",
    "        \n",
    "        features_dict['rise_time'].append(rise_time)\n",
    "        features_dict['decay_time'].append(decay_time)\n",
    "    \n",
    "    # 배열로 변환\n",
    "    for key in features_dict:\n",
    "        if key != 'waveforms':\n",
    "            features_dict[key] = np.array(features_dict[key])\n",
    "    \n",
    "    return features_dict\n",
    "\n",
    "try:\n",
    "    # 정상 신경 신호에서 스파이크 검출\n",
    "    signal_data = normal_df['channel_1'].values\n",
    "    time_data = normal_df['time'].values\n",
    "    \n",
    "    # 필터링 적용\n",
    "    filtered_signal = filter_neural_signal(signal_data)\n",
    "    \n",
    "    # 스파이크 검출\n",
    "    spike_indices = detect_spikes(filtered_signal, threshold_factor=3.0)\n",
    "    \n",
    "    # 스파이크 특성 추출\n",
    "    features = extract_spike_features(filtered_signal, spike_indices)\n",
    "    \n",
    "    # 스파이크 검출 결과 시각화\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # 신호와 검출된 스파이크\n",
    "    plt.subplot(2, 1, 1)\n",
    "    display_samples = 1000  # 첫 1초 데이터\n",
    "    plt.plot(time_data[:display_samples], filtered_signal[:display_samples], 'b-')\n",
    "    \n",
    "    # 검출된 스파이크 표시\n",
    "    spike_mask = (spike_indices < display_samples)\n",
    "    if np.any(spike_mask):\n",
    "        displayed_spikes = spike_indices[spike_mask]\n",
    "        plt.plot(time_data[displayed_spikes], filtered_signal[displayed_spikes], 'ro', markersize=8)\n",
    "    \n",
    "    plt.title('신경 신호와 검출된 스파이크', fontsize=14)\n",
    "    plt.xlabel('시간 (초)', fontsize=12)\n",
    "    plt.ylabel('진폭', fontsize=12)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 정규화된 스파이크 파형 중첩 표시\n",
    "    plt.subplot(2, 1, 2)\n",
    "    if len(features['waveforms']) > 0:\n",
    "        # 최대 30개까지만 표시\n",
    "        max_display = min(30, len(features['waveforms']))\n",
    "        for i in range(max_display):\n",
    "            waveform = features['waveforms'][i]\n",
    "            # 진폭 정규화\n",
    "            normalized = (waveform - np.min(waveform)) / (np.max(waveform) - np.min(waveform))\n",
    "            plt.plot(np.arange(len(normalized)), normalized, 'b-', alpha=0.5)\n",
    "        \n",
    "        # 평균 파형 표시\n",
    "        avg_waveform = np.mean(features['waveforms'][:max_display], axis=0)\n",
    "        normalized_avg = (avg_waveform - np.min(avg_waveform)) / (np.max(avg_waveform) - np.min(avg_waveform))\n",
    "        plt.plot(np.arange(len(normalized_avg)), normalized_avg, 'r-', linewidth=2, label='평균 파형')\n",
    "        \n",
    "        plt.title('정규화된 스파이크 파형', fontsize=14)\n",
    "        plt.xlabel('샘플', fontsize=12)\n",
    "        plt.ylabel('정규화된 진폭', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, '검출된 스파이크 없음', horizontalalignment='center', verticalalignment='center', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 스파이크 특성 통계\n",
    "    if len(features['amplitude']) > 0:\n",
    "        print(f\"검출된 스파이크 수: {len(features['amplitude'])}\")\n",
    "        print(f\"평균 스파이크 진폭: {np.mean(features['amplitude']):.3f} ± {np.std(features['amplitude']):.3f}\")\n",
    "        print(f\"평균 스파이크 폭: {np.mean(features['width']):.3f} ± {np.std(features['width']):.3f} 샘플\")\n",
    "        print(f\"평균 상승 시간: {np.mean(features['rise_time']):.3f} ± {np.std(features['rise_time']):.3f} 샘플\")\n",
    "        print(f\"평균 감쇠 시간: {np.mean(features['decay_time']):.3f} ± {np.std(features['decay_time']):.3f} 샘플\")\n",
    "        \n",
    "        # 스파이크 발화율 계산 (1초 단위 윈도우)\n",
    "        fs = 1000  # 샘플링 주파수 (Hz)\n",
    "        firing_rate = len(features['amplitude']) / (len(signal_data) / fs)\n",
    "        print(f\"평균 발화율: {firing_rate:.2f} Hz\")\n",
    "    else:\n",
    "        print(\"검출된 스파이크가 없습니다.\")\n",
    "except NameError:\n",
    "    print(\"데이터가 로드되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 시계열 데이터 준비 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(data, sequence_length=50, overlap=0, step=1):\n",
    "    \"\"\"\n",
    "    신경 신호 데이터를 시퀀스로 변환합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like, shape (samples, features)\n",
    "        시퀀스로 변환할 데이터\n",
    "    sequence_length : int\n",
    "        각 시퀀스의 길이\n",
    "    overlap : int\n",
    "        연속된 시퀀스 간 중첩 샘플 수\n",
    "    step : int\n",
    "        시퀀스 시작점 간 단계 크기\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    sequences : array-like, shape (n_sequences, sequence_length, features)\n",
    "        생성된 시퀀스 배열\n",
    "    \"\"\"\n",
    "    n_samples, n_features = data.shape\n",
    "    \n",
    "    effective_step = sequence_length - overlap\n",
    "    if effective_step <= 0:\n",
    "        raise ValueError(\"overlap이 sequence_length보다 크거나 같을 수 없습니다.\")\n",
    "    \n",
    "    # 시퀀스 시작점 계산\n",
    "    start_indices = list(range(0, n_samples - sequence_length + 1, step))\n",
    "    n_sequences = len(start_indices)\n",
    "    \n",
    "    # 결과 배열 초기화\n",
    "    sequences = np.zeros((n_sequences, sequence_length, n_features))\n",
    "    \n",
    "    # 시퀀스 추출\n",
    "    for i, start_idx in enumerate(start_indices):\n",
    "        end_idx = start_idx + sequence_length\n",
    "        sequences[i] = data[start_idx:end_idx]\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "try:\n",
    "    # 신경 신호 데이터 준비\n",
    "    # 정상 신호와 손상된 신호 모두 활용\n",
    "    normal_signals = normal_df.iloc[:, 1:].values  # time 열 제외\n",
    "    damaged_signals = damaged_df.iloc[:, 1:].values  # time 열 제외\n",
    "    \n",
    "    # 데이터 정규화\n",
    "    scaler = StandardScaler()\n",
    "    normal_scaled = scaler.fit_transform(normal_signals)\n",
    "    damaged_scaled = scaler.transform(damaged_signals)  # 같은 스케일러 사용\n",
    "    \n",
    "    # 시퀀스 준비\n",
    "    sequence_length = 100  # 100ms (1000Hz 가정)\n",
    "    normal_sequences = prepare_sequences(normal_scaled, sequence_length=sequence_length, step=50)\n",
    "    damaged_sequences = prepare_sequences(damaged_scaled, sequence_length=sequence_length, step=50)\n",
    "    \n",
    "    print(f\"정상 신호 시퀀스 형태: {normal_sequences.shape}\")\n",
    "    print(f\"손상된 신호 시퀀스 형태: {damaged_sequences.shape}\")\n",
    "    \n",
    "    # 시퀀스 시각화\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # 정상 신호 시퀀스 샘플\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for i in range(min(5, normal_sequences.shape[0])):\n",
    "        for j in range(normal_sequences.shape[2]):  # 모든 채널 표시\n",
    "            plt.plot(np.arange(sequence_length)/1000, normal_sequences[i, :, j] + j*2, alpha=0.7)\n",
    "    \n",
    "    plt.title('정상 신경 신호 시퀀스 샘플', fontsize=14)\n",
    "    plt.xlabel('시간 (초)', fontsize=12)\n",
    "    plt.ylabel('정규화된 진폭 + 오프셋', fontsize=12)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 손상된 신호 시퀀스 샘플\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for i in range(min(5, damaged_sequences.shape[0])):\n",
    "        for j in range(damaged_sequences.shape[2]):  # 모든 채널 표시\n",
    "            plt.plot(np.arange(sequence_length)/1000, damaged_sequences[i, :, j] + j*2, alpha=0.7)\n",
    "    \n",
    "    plt.title('손상된 신경 신호 시퀀스 샘플', fontsize=14)\n",
    "    plt.xlabel('시간 (초)', fontsize=12)\n",
    "    plt.ylabel('정규화된 진폭 + 오프셋', fontsize=12)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 라벨 생성 (정상=1, 손상=0)\n",
    "    y_normal = np.ones(normal_sequences.shape[0])\n",
    "    y_damaged = np.zeros(damaged_sequences.shape[0])\n",
    "    \n",
    "    # 학습/테스트 데이터셋 생성 예제\n",
    "    X = np.vstack([normal_sequences, damaged_sequences])\n",
    "    y = np.hstack([y_normal, y_damaged])\n",
    "    \n",
    "    print(f\"전체 데이터셋 형태: X.shape={X.shape}, y.shape={y.shape}\")\n",
    "    print(f\"클래스 분포: 정상={np.sum(y==1)}, 손상={np.sum(y==0)}\")\n",
    "except NameError:\n",
    "    print(\"데이터가 로드되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 주파수 영역 분석\n",
    "\n",
    "신경 신호의 주파수 특성을 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectrogram(signal_data, fs=1000, nperseg=256, noverlap=128):\n",
    "    \"\"\"\n",
    "    신호의 스펙트로그램을 계산합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal_data : array-like\n",
    "        스펙트로그램을 계산할 신호 데이터\n",
    "    fs : float\n",
    "        샘플링 주파수 (Hz)\n",
    "    nperseg : int\n",
    "        각 세그먼트의 길이\n",
    "    noverlap : int\n",
    "        연속된 세그먼트 간 중첩 샘플 수\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    f : array-like\n",
    "        주파수 축 값\n",
    "    t : array-like\n",
    "        시간 축 값\n",
    "    Sxx : array-like\n",
    "        스펙트로그램 (파워 밀도)\n",
    "    \"\"\"\n",
    "    f, t, Sxx = signal.spectrogram(signal_data, fs=fs, nperseg=nperseg, noverlap=noverlap)\n",
    "    return f, t, Sxx\n",
    "\n",
    "def compute_psd(signal_data, fs=1000, nperseg=1024):\n",
    "    \"\"\"\n",
    "    신호의 파워 스펙트럼 밀도(PSD)를 계산합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal_data : array-like\n",
    "        PSD를 계산할 신호 데이터\n",
    "    fs : float\n",
    "        샘플링 주파수 (Hz)\n",
    "    nperseg : int\n",
    "        각 세그먼트의 길이\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    f : array-like\n",
    "        주파수 축 값\n",
    "    Pxx : array-like\n",
    "        파워 스펙트럼 밀도\n",
    "    \"\"\"\n",
    "    f, Pxx = signal.welch(signal_data, fs=fs, nperseg=nperseg)\n",
    "    return f, Pxx\n",
    "\n",
    "try:\n",
    "    # 신경 신호 유형별 주파수 분석\n",
    "    fs = 1000  # 샘플링 주파수 (Hz)\n",
    "    \n",
    "    # 비교할 신호 선택\n",
    "    normal_signal = normal_df['channel_1'].values\n",
    "    damaged_signal = damaged_df['channel_1'].values\n",
    "    stim_signal = stim_response_df['channel_1'].values\n",
    "    noisy_signal = noisy_df['channel_1'].values\n",
    "    \n",
    "    # 필터링 적용\n",
    "    filtered_normal = filter_neural_signal(normal_signal)\n",
    "    filtered_damaged = filter_neural_signal(damaged_signal)\n",
    "    filtered_stim = filter_neural_signal(stim_signal)\n",
    "    filtered_noisy = filter_neural_signal(noisy_signal)\n",
    "    \n",
    "    # 파워 스펙트럼 밀도 계산\n",
    "    f_normal, Pxx_normal = compute_psd(filtered_normal, fs=fs)\n",
    "    f_damaged, Pxx_damaged = compute_psd(filtered_damaged, fs=fs)\n",
    "    f_stim, Pxx_stim = compute_psd(filtered_stim, fs=fs)\n",
    "    f_noisy, Pxx_noisy = compute_psd(filtered_noisy, fs=fs)\n",
    "    \n",
    "    # PSD 비교 시각화\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.semilogy(f_normal, Pxx_normal, 'b-', label='정상 신호', alpha=0.7)\n",
    "    plt.semilogy(f_damaged, Pxx_damaged, 'r-', label='손상된 신호', alpha=0.7)\n",
    "    plt.semilogy(f_stim, Pxx_stim, 'g-', label='자극 반응 신호', alpha=0.7)\n",
    "    plt.semilogy(f_noisy, Pxx_noisy, 'k-', label='잡음이 많은 신호', alpha=0.7)\n",
    "    \n",
    "    plt.title('신경 신호 유형별 파워 스펙트럼 밀도 비교', fontsize=14)\n",
    "    plt.xlabel('주파수 (Hz)', fontsize=12)\n",
    "    plt.ylabel('파워 스펙트럼 밀도 (dB/Hz)', fontsize=12)\n",
    "    plt.xlim(0, 200)  # 0-200Hz 범위만 표시\n",
    "    plt.grid(True, which='both', linestyle='--', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 스펙트로그램 계산 및 시각화\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    \n",
    "    # 정상 신호 스펙트로그램\n",
    "    plt.subplot(2, 2, 1)\n",
    "    f, t, Sxx = compute_spectrogram(filtered_normal[:3000], fs=fs)  # 3초 데이터\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud', cmap='viridis')\n",
    "    plt.title('정상 신경 신호 스펙트로그램', fontsize=12)\n",
    "    plt.xlabel('시간 (초)', fontsize=10)\n",
    "    plt.ylabel('주파수 (Hz)', fontsize=10)\n",
    "    plt.ylim(0, 200)  # 0-200Hz 범위만 표시\n",
    "    plt.colorbar(label='파워 (dB)')\n",
    "    \n",
    "    # 손상된 신호 스펙트로그램\n",
    "    plt.subplot(2, 2, 2)\n",
    "    f, t, Sxx = compute_spectrogram(filtered_damaged[:3000], fs=fs)  # 3초 데이터\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud', cmap='viridis')\n",
    "    plt.title('손상된 신경 신호 스펙트로그램', fontsize=12)\n",
    "    plt.xlabel('시간 (초)', fontsize=10)\n",
    "    plt.ylabel('주파수 (Hz)', fontsize=10)\n",
    "    plt.ylim(0, 200)  # 0-200Hz 범위만 표시\n",
    "    plt.colorbar(label='파워 (dB)')\n",
    "    \n",
    "    # 자극 반응 신호 스펙트로그램\n",
    "    plt.subplot(2, 2, 3)\n",
    "    f, t, Sxx = compute_spectrogram(filtered_stim[:3000], fs=fs)  # 3초 데이터\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud', cmap='viridis')\n",
    "    plt.title('자극 반응 신호 스펙트로그램', fontsize=12)\n",
    "    plt.xlabel('시간 (초)', fontsize=10)\n",
    "    plt.ylabel('주파수 (Hz)', fontsize=10)\n",
    "    plt.ylim(0, 200)  # 0-200Hz 범위만 표시\n",
    "    plt.colorbar(label='파워 (dB)')\n",
    "    \n",
    "    # 잡음이 많은 신호 스펙트로그램\n",
    "    plt.subplot(2, 2, 4)\n",
    "    f, t, Sxx = compute_spectrogram(filtered_noisy[:3000], fs=fs)  # 3초 데이터\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud', cmap='viridis')\n",
    "    plt.title('잡음이 많은 신호 스펙트로그램', fontsize=12)\n",
    "    plt.xlabel('시간 (초)', fontsize=10)\n",
    "    plt.ylabel('주파수 (Hz)', fontsize=10)\n",
    "    plt.ylim(0, 200)  # 0-200Hz 범위만 표시\n",
    "    plt.colorbar(label='파워 (dB)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except NameError:\n",
    "    print(\"데이터가 로드되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 결론 및 요약\n",
    "\n",
    "이 노트북에서는 다양한 유형의 신경 신호 데이터를 생성, 탐색, 분석하고 전처리하는 방법을 살펴보았습니다. 주요 내용은 다음과 같습니다:\n",
    "\n",
    "1. **데이터 생성 및 탐색**: 여러 유형의 신경 신호 데이터(정상, 손상, 자극 반응, 잡음이 많은)를 생성하고 기본 특성을 탐색했습니다.\n",
    "\n",
    "2. **신호 전처리**: 노이즈 필터링, 스파이크 검출, 특성 추출 등의 전처리 기법을 적용하여 신경 신호의 유의미한 정보를 추출했습니다.\n",
    "\n",
    "3. **시계열 데이터 준비**: 딥러닝 모델 학습을 위한 시퀀스 데이터 생성 및 정규화 방법을 알아보았습니다.\n",
    "\n",
    "4. **주파수 영역 분석**: PSD 및 스펙트로그램을 통해 신경 신호의 주파수 특성을 분석했습니다.\n",
    "\n",
    "이러한 방법론은 적응형 신경 전기자극 시스템에서 신경 신호를 분석하고 자극 효과를 평가하는 데 중요한 기반이 됩니다. 처리된 데이터는 강화학습 에이전트나 LSTM과 같은 딥러닝 모델을 학습시키는 데 사용될 수 있으며, 이를 통해 개인별 최적화된 자극 프로토콜을 개발할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
